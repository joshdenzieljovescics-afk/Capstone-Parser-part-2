import io
import json
import os
import re
import statistics
from datetime import datetime
import pdfplumber
from flask import Flask, request, jsonify
from flask_cors import CORS
from pprint import pprint
from dotenv import load_dotenv
import fitz
import base64
from openai import OpenAI
import uuid  # Add this import at the top

load_dotenv()

# --- Flask setup ---
app = Flask(__name__)
CORS(app)

# --- OpenAI setup (commented) ---
load_dotenv(override=True)  # make sure dotenv is loaded
openai_api_key = os.environ.get("OPENAI_API_KEY")

if not openai_api_key:
    print("‚ö†Ô∏è Could not find OPENAI_API_KEY in environment. Falling back to dotenv...")
    from dotenv import dotenv_values
    env_vars = dotenv_values(".env")
    openai_api_key = env_vars.get("OPENAI_API_KEY")

if not openai_api_key:
    raise RuntimeError("‚ùå OPENAI_API_KEY environment variable is not set!")

client = OpenAI(api_key=openai_api_key)


# --- STEP 1: Extract text, tables, figures/images, fonts ---
def lines_from_chars(page, line_tol=5, word_tol=None):
    """
    Group page.chars into lines; return list of line dicts with
    text, bbox, font_size, style, spacing metadata, and per-word font info.
    """
    chars = sorted(
        page.chars,
        key=lambda c: (round(c.get("top", 0), 1), round(c.get("x0", 0), 1))
    )
    if not chars:
        return []
    
 # Calculate adaptive word tolerance if not provided
    if word_tol is None:
        font_sizes = [c.get("size", 12) for c in chars if c.get("size")]
        avg_font_size = statistics.median(font_sizes) if font_sizes else 12.0
        word_tol = avg_font_size * 0.4  # 40% of font size for word separation
        


    # --- group chars into lines
    lines = []
    current = [chars[0]]
    for ch in chars[1:]:
        if abs(ch.get("top", 0) - current[0].get("top", 0)) < line_tol:
            current.append(ch)
        else:
            lines.append(current)
            current = [ch]
    if current:
        lines.append(current)

    # --- build line objects
    line_objs = []
    prev_bottom = None

    # Get page number from page object for unique ID generation
    page_number = getattr(page, 'page_number', 1)

    for idx, ln in enumerate(lines):
        # Calculate line-specific word tolerance
        line_font_sizes = [c.get("size", 12) for c in ln if c.get("size")]
        line_avg_font = statistics.median(line_font_sizes) if line_font_sizes else 12.0
        line_word_tol = line_avg_font * 0.4  # Per-line adaptive tolerance

        # group chars into words within the line
        words = []
        current_word = [ln[0]]
        for ch in ln[1:]:
            prev = current_word[-1]
            gap = abs(ch.get("x0", 0) - prev.get("x1", 0))
            
            # Debug problematic gaps
            # if gap > line_word_tol:
            #     print(f"[DEBUG [PROBLIMATIC]]")
            #     print(f"[DEBUG] Word break: '{prev.get('text', '')}'->'{ch.get('text', '')}' gap={gap:.2f} tol={line_word_tol:.2f}")
            
            if gap > line_word_tol:
                words.append(current_word)
                current_word = [ch]
            else:
                current_word.append(ch)
        if current_word:
            words.append(current_word)

        word_objs = []
        for w in words:
            text = "".join(c.get("text", "") for c in w).strip()
            # print(f"Word: '{text}' | Length: {len(w)} | Chars: {[c.get('text', '') for c in w]}")
            if not text:
                continue
            l = min(c.get("x0", 0) for c in w)
            t = min(c.get("top", 0) for c in w)
            r = max(c.get("x1", 0) for c in w)
            b = max(c.get("bottom", 0) for c in w)

            sizes = [float(c.get("size", 0)) for c in w if c.get("size") is not None]
            font_size = round(statistics.median(sizes), 2) if sizes else None

            fonts = [c.get("fontname", "") for c in w]
            bold = any("Bold" in f for f in fonts)
            italic = any("Italic" in f or "Oblique" in f for f in fonts)

            word_objs.append({
                "text": text,
                "box": {"l": l, "t": t, "r": r, "b": b},
                "font_size": font_size,
                "bold": bold,
                "italic": italic,
            })

        if not word_objs:
            continue

        l = min(w["box"]["l"] for w in word_objs)
        t = min(w["box"]["t"] for w in word_objs)
        r = max(w["box"]["r"] for w in word_objs)
        b = max(w["box"]["b"] for w in word_objs)

        # spacing metadata
        line_breaks_before = 0
        if prev_bottom is not None and (t - prev_bottom) > line_tol:
            line_breaks_before = 1
        prev_bottom = b

        # Generate unique line ID with page prefix
        unique_line_id = f"p{page_number}-ln-{idx}"

        line_objs.append({
            "id": unique_line_id,
            "type": "text",
            "text": " ".join(w["text"] for w in word_objs),
            "box": {"l": l, "t": t, "r": r, "b": b},
            "indent": l,
            "line_breaks_before": line_breaks_before,
            "line_breaks_after": 0,  # to be filled later
            "words": word_objs,
        })


    # --- fill line_breaks_after
    for i in range(len(line_objs) - 1):
        gap = line_objs[i+1]["box"]["t"] - line_objs[i]["box"]["b"]
        if gap > line_tol:
            line_objs[i]["line_breaks_after"] = 1

    return line_objs

def extract_tables_with_bbox(page):
    """
    Use page.find_tables() to get table objects and their bbox.
    Returns list of dicts: { type: 'table', 'table': rows, 'box': {l,t,r,b} }
    """
    tables = []
    found = page.find_tables()

     # Get page number for unique ID generation
    page_number = getattr(page, 'page_number', 1)

    for table_idx, t in enumerate(found):
        bbox = getattr(t, "bbox", None) or getattr(t, "_bbox", None)
        if bbox and len(bbox) == 4:
            l, ttop, r, btm = bbox
        else:
            # fallback: compute bbox from extracted table rows if possible, else skip
            rows = t.extract()
            if rows:
                # try to find words in table rows to estimate bbox (best-effort)
                # fallback to whole page if can't compute
                try:
                    # collect text tokens, find their bounding boxes via page.extract_words
                    words = page.extract_words()
                    # naive fallback -> whole page dims
                    l, ttop, r, btm = 0, 0, page.width, page.height
                except Exception:
                    l, ttop, r, btm = 0, 0, page.width, page.height
            else:
                l, ttop, r, btm = 0, 0, page.width, page.height

        table_rows = t.extract()
        unique_table_id = f"p{page_number}-tbl-{table_idx}"

        tables.append({
            "id": unique_table_id,  # ‚úÖ Add unique ID
            "type": "table",
            "table": table_rows,
            "box": {"l": l, "t": ttop, "r": r, "b": btm},
        })
    return tables


def line_intersects_bbox(line, bbox, margin=1.0):
    """
    Return True if line's vertical midpoint is inside bbox vertically and horizontally overlaps.
    margin: small tolerance
    """
    line_mid = (line["box"]["t"] + line["box"]["b"]) / 2.0
    tb_top, tb_bottom = bbox["t"] - margin, bbox["b"] + margin
    horiz_overlap = not (line["box"]["r"] < bbox["l"] or line["box"]["l"] > bbox["r"])
    return (tb_top <= line_mid <= tb_bottom) and horiz_overlap

# --- Extract images using PyMuPDF ---
def extract_images_with_bbox_pymupdf(file_bytes, page_number):
    """
    Uses xref placement rects to get true positions of images on the page.
    Returns list of dicts with unique IDs.
    """
    images = []
    with fitz.open(stream=file_bytes, filetype="pdf") as doc:
        page = doc[page_number]

        # Enumerate all image xrefs used on this page
        xref_rows = page.get_images(full=True)  # [(xref, smask, w, h, bpc, cs, name, ...), ...]
        if not xref_rows:
            return images
        
        image_counter = 0  # Counter for multiple placements of same xref

        for xref_idx, row in enumerate(xref_rows):  # ‚úÖ Use enumerate
            xref = row[0]
            rects = page.get_image_rects(xref)  # all placements (may be multiple)
            if not rects:
                # No visible placement for this xref on this page
                continue

            # Build pixmap once per xref
            try:
                pix = fitz.Pixmap(doc, xref)
                if pix.n > 4:  # convert CMYK/others to RGB
                    pix = fitz.Pixmap(fitz.csRGB, pix)
                img_b64 = base64.b64encode(pix.tobytes("png")).decode("utf-8")
            except Exception as e:
                print(f"[WARN] xref={xref} pixmap failed: {e}")
                continue

            for rect in rects:
                l, t, r, b = float(rect.x0), float(rect.y0), float(rect.x1), float(rect.y1)

                # Generate unique image ID with page prefix
                unique_image_id = f"p{page_number + 1}-img-{image_counter}"
                image_counter += 1

                images.append({
                    "id": unique_image_id,  # ‚úÖ Add unique ID
                    "type": "image",
                    "subtype": "embedded",
                    "box": {"l": l, "t": t, "r": r, "b": b},
                    "page": page_number + 1,
                    "image_b64": img_b64,
                })

    return images


    # # --- Method 2: Embedded images (from resources, may lack bbox)
    # for img in page.get_images(full=True):
    #     xref = img[0]
    #     try:
    #         pix = fitz.Pixmap(doc, xref)
    #         if pix.n > 4:
    #             pix = fitz.Pixmap(fitz.csRGB, pix)
    #         img_b64 = base64.b64encode(pix.tobytes("png")).decode("utf-8")
    #         images.append({
    #             "type": "image",
    #             "subtype": "embedded",
    #             # fallback bbox = full page (UI can still box it)
    #             "box": {"l": 0, "t": 0, "r": page.rect.width, "b": page.rect.height},
    #             "page": page_number + 1,
    #             "image_b64": img_b64,
    #         })
    #     except Exception as e:
    #         print(f"[WARN] Embedded image failed: {e}")
    #         continue

    # print(f"[DEBUG] Page {page_number+1}: Found {len(images)} images "
    #       f"(subtypes: {[im.get('subtype', im['type']) for im in images]})")

    # return images

def assemble_elements(file_bytes, page, page_number):
    """
    Build ordered elements for the page:
    - get text lines (with font/style/spacing metadata)
    - get tables (with bbox)
    - get images (with bbox/base64)
    - remove lines that overlap table bboxes
    - combine into one list sorted by vertical position
    """
    text_lines = lines_from_chars(page)  # enriched with style + spacing + word-level info
    tables = extract_tables_with_bbox(page)
    images = extract_images_with_bbox_pymupdf(file_bytes, page_number)
    
    # --- Filter out text lines that overlap with any table bbox
    filtered_lines = []
    for ln in text_lines:
        in_any_table = any(line_intersects_bbox(ln, tb["box"]) for tb in tables)
        if not in_any_table:
            filtered_lines.append(ln)

    # --- Merge all elements into a unified list
    elements = []
    for ln in filtered_lines:
        elements.append({
            **ln,  # contains line-level text, box, spacing, and word-level list
            "page": page_number + 1,
            "top": ln["box"]["t"],
        })
    for tb in tables:
        elements.append({
            **tb,
            "page": page_number + 1,
            "top": tb["box"]["t"],
        })
    for im in images:
        elements.append({
            **im,
            "page": page_number + 1,
            "top": im["box"]["t"],
        })

    # --- Sort by top coordinate, fallback to left (chronological order)
    elements.sort(key=lambda e: (e["top"], e["box"].get("l", 0)))

    return elements

# def extract_images_with_bbox(page):
#     """
#     Extract images with their bounding boxes.
#     pdfplumber gives page.images as list of dicts.
#     We'll standardize to {type: 'image', box: {...}, attrs: {...}}
#     """
#     images = []
#     for im in page.images:
#         l = im.get("x0", 0)
#         t = im.get("top", 0)
#         r = im.get("x1", 0)
#         b = im.get("bottom", 0)
#         images.append({
#             "type": "image",
#             "box": {"l": l, "t": t, "r": r, "b": b},
#             "attrs": {
#                 "width": r - l,
#                 "height": b - t,
#                 "name": im.get("name"),
#                 "stream": im.get("stream"),
#                 "page_number": page.page_number
#             }
#         })
    # return images



def build_simplified_view_from_elements(elements, gap_multiplier=1.5):
    """
    Build a simplified string preserving structure:
    - Preserve explicit line breaks (line_breaks_before/after) from extraction
    - Fallback to gap-based blank lines when explicit counts aren't present
    - Include a page header once per page
    - Place images inline at their positions with bbox info
    - Use inline markers for font size, bold, italic
    """
    lines_out = []

    # Group elements by page
    pages = {}
    for el in elements:
        page_no = el.get("page", 1)
        pages.setdefault(page_no, []).append(el)

    for page_no in sorted(pages.keys()):
        page_elems = pages[page_no]
        # Sort by visual order
        page_elems.sort(key=lambda e: (e.get("top", e["box"]["t"]), e["box"].get("l", 0)))

        # Median line height per page (gap fallback)
        heights = [
            (el["box"]["b"] - el["box"]["t"])
            for el in page_elems
            if el.get("type") == "text" and "box" in el
        ]
        median_height = statistics.median(heights) if heights else 12.0
        threshold = median_height * gap_multiplier

        # Page header (once)
        lines_out.append(f"[PAGE={page_no}]")

        prev_bottom = None
        active_size = None  # track active font size block

        for el in page_elems:
            top = el["box"]["t"]
            bottom = el["box"]["b"]

            # Explicit breaks BEFORE, else gap fallback
            lb_before = int(el.get("line_breaks_before", 0) or 0)
            if lb_before > 0:
                lines_out.extend([""] * lb_before)
            else:
                if prev_bottom is not None:
                    gap = top - prev_bottom
                    if gap > threshold:
                        lines_out.append("")

            if el["type"] == "text":
                words_out = []

                # Compute line font size (median of words)
                word_sizes = [w.get("font_size") for w in el.get("words", []) if w.get("font_size")]
                line_size = statistics.median(word_sizes) if word_sizes else None

                # Emit size tag when size changes
                if line_size and line_size != active_size:
                    if active_size:
                        words_out.append("</s>")
                    words_out.append(f"<s={int(line_size)}>")
                    active_size = line_size

                # Render words with style markers
                for w in el.get("words", []):
                    text = w.get("text", "")
                    bold = w.get("bold", False)
                    italic = w.get("italic", False)

                    if bold and italic:
                        words_out.append(f"*_ {text} _*")
                    elif bold:
                        words_out.append(f"*{text}*")
                    elif italic:
                        words_out.append(f"_{text}_")
                    else:
                        words_out.append(text)

                # Do not strip to preserve trailing spaces if present
                line_str = " ".join(words_out)
                lines_out.append(line_str)
                prev_bottom = bottom

            elif el["type"] == "table":
                lines_out.append("[TABLE]")
                for row in el.get("table", []):
                    lines_out.append(" | ".join(str(cell) for cell in row))
                lines_out.append("[/TABLE]")
                prev_bottom = bottom

            elif el["type"] == "image":
                bx = el.get("box", {})
                lines_out.append(
                    f"[IMAGE page={page_no} l={bx.get('l', 0):.1f} t={bx.get('t', 0):.1f} "
                    f"r={bx.get('r', 0):.1f} b={bx.get('b', 0):.1f}]"
                )
                prev_bottom = bottom

            # Explicit breaks AFTER
            lb_after = int(el.get("line_breaks_after", 0) or 0)
            if lb_after > 0:
                lines_out.extend([""] * lb_after)

        # Close active size at end of page
        if active_size:
            lines_out.append("</s>")
            active_size = None

        # Page separator
        lines_out.append("")

    # Trim trailing blanks
    while lines_out and lines_out[-1] == "":
        lines_out.pop()

    return "\n".join(lines_out)

# --- STEP 3: Endpoint ---
@app.route('/parse-pdf', methods=['POST'])
def parse_pdf():
    if 'file' not in request.files:
        return jsonify({"error": "No file part"}), 400

    file = request.files['file']
    if not file.filename or not file.filename.lower().endswith('.pdf'):
        return jsonify({"error": "File is not a PDF"}), 400

    try:
        file_bytes = file.read()
        structured = []

        with pdfplumber.open(io.BytesIO(file_bytes)) as pdf:
            for i, page in enumerate(pdf.pages):
                page_elems = assemble_elements(file_bytes, page, i)  # ‚úÖ pass both args
                                # annotate with page number and page dims
                for el in page_elems:
                    el["page"] = i + 1
                    el["page_width"] = page.width
                    el["page_height"] = page.height
                structured.extend(page_elems)

        simplified = build_simplified_view_from_elements(structured)
        
        with open("structured_output_v3.json", "w") as f:
            json.dump(structured, f, indent=2)

        # Debug preview
        print("\n[DEBUG] Simplified view (preview):\n")
        print(simplified[:5000])
    
        # Collect images from structured
        # images = [el for el in structured if el.get("type") == "image"]
        # import base64

        # for img in images:
        #     print(f"[IMAGE] page={img.get('page')}, box={img.get('box')}, subtype={img.get('subtype')}")
        #     if "image_b64" in img:
        #         print(f"Base64 preview: {img['image_b64'][:80]}...")  # Print first 80 chars for preview

        return jsonify({
            "simplified": simplified,
            "structured": structured
        }), 200  # ‚úÖ explicit success code

    except Exception as e:
        import traceback
        # print("[ERROR]", traceback.format_exc())  # ‚úÖ print full stacktrace for debugging
        return jsonify({"error": f"Internal server error: {str(e)}"}), 500


def _normalize(s: str) -> str:
    return re.sub(r"\s+", " ", (s or "").strip())

def _anchor_chunks_to_pdf(result_chunks, structured, image_bindings, source_filename):
    """
    Anchor AI result chunks back to PDF coordinates by matching text content.
    """
    
    # Build searchable list of text lines from structured data
    pdf_lines = _pdf_lines_for_match(structured)
    used_line_ids = set()  # ‚úÖ Track used linesf
    
    for chunk_idx, chunk in enumerate(result_chunks):
        chunk_text = chunk.get("text", "")
        if not chunk_text.strip():
            continue
            
        # Split chunk text into individual lines
        chunk_lines = [line.strip() for line in chunk_text.split('\n') if line.strip()]  
        
        # Find matching lines in structured output
        matched_lines = []
        matched_line_ids = []
        start_idx = 0
        
        for chunk_line in chunk_lines:
            match_result = _match_chunk_to_lines_with_exclusion(
                chunk_line, pdf_lines, start_idx, used_line_ids
            )
            if match_result:
                matched_idx, matched_line_list = match_result
                matched_lines.extend(matched_line_list)
                
                # Extract IDs and mark as used
                for line in matched_line_list:
                    line_id = line.get("id", "")
                    if line_id:
                        matched_line_ids.append(line_id)
                        used_line_ids.add(line_id)  # ‚úÖ Mark as used
                
                start_idx = matched_idx + len(matched_line_list)
                print(f"[DEBUG] Matched chunk line '{chunk_line[:30]}...' to {len(matched_line_list)} PDF lines")
            else:
                print(f"[WARN] Could not match chunk line: '{chunk_line[:50]}...'")
        
        # ... rest of the function remains the same

        # ‚úÖ Generate unique chunk ID
        chunk_id = f"chunk-{chunk_idx}-{str(uuid.uuid4())[:8]}"

        # Calculate encompassing bounding box from matched lines
        if matched_lines:
            chunk_box = _calculate_chunk_box(matched_lines)
            
            # Add box and page info to chunk metadata
            if "metadata" not in chunk:
                chunk["metadata"] = {}

            chunk["id"] = chunk_id  # ‚úÖ Add unique ID to chunk root level
            chunk["metadata"]["box"] = chunk_box
            chunk["metadata"]["page"] = matched_lines[0].get("page", 1)
            chunk["metadata"]["source_file"] = source_filename
            chunk["metadata"]["line_count"] = len(matched_lines)
            chunk["metadata"]["anchored"] = True  # Flag to indicate successful anchoring
            chunk["metadata"]["matched_line_ids"] = matched_line_ids  # ‚úÖ Add line IDs
            chunk["metadata"]["created_at"] = datetime.now().isoformat()
            
            print(f"[DEBUG] Anchored chunk: page={chunk['metadata']['page']}, "
                  f"lines={len(matched_lines)}, box={chunk_box}")
        else:
            # Mark as unanchored but still add metadata structure
            if "metadata" not in chunk:
                chunk["metadata"] = {}
            
            chunk["metadata"]["anchored"] = False
            chunk["metadata"]["source_file"] = source_filename
            chunk["metadata"]["matched_line_ids"] = []  # ‚úÖ Empty array for unanchored
            chunk["metadata"]["created_at"] = datetime.now().isoformat()
            print(f"[WARN] No lines matched for chunk: '{chunk_text[:50]}...'")
    
    return result_chunks  # Return the modified chunks

def _match_chunk_to_lines_with_exclusion(chunk_text, pdf_lines, start_idx=0, used_line_ids=None):
    """
    Enhanced matching that excludes already used lines to prevent overlap between chunks.
    Always returns (index, [list_of_lines]) for consistency.
    """
    if used_line_ids is None:
        used_line_ids = set()
        
    normalized_chunk = _normalize(chunk_text)
    
    print(f"[DEBUG] Matching chunk: '{chunk_text[:50]}...' (excluding {len(used_line_ids)} used lines)")
    
    # First try single line matches
    for i in range(start_idx, len(pdf_lines)):
        line = pdf_lines[i]
        line_id = line.get("id", "")
        
        # ‚úÖ Skip if line already used
        if line_id in used_line_ids:
            print(f"[DEBUG] Skipping already used line: {line_id}")
            continue
            
        line_text = line.get("text", "")
        normalized_line = _normalize(line_text)
        
        print(f"[DEBUG] Checking line {i} ({line_id}): '{line_text[:30]}...'")
        
        # Exact match
        if normalized_chunk == normalized_line:
            print(f"[DEBUG] EXACT MATCH found at line {i}")
            return (i, [line])
        
        # Partial match (chunk text contained in line)
        if normalized_chunk in normalized_line:
            print(f"[DEBUG] PARTIAL MATCH found at line {i}")
            return (i, [line])
        
        # More restrictive fuzzy match to prevent false positives
        if len(normalized_chunk) > 15:  # Higher threshold
            chunk_words = set(normalized_chunk.split())
            line_words = set(normalized_line.split())
            common_words = chunk_words & line_words
            overlap_ratio = len(common_words) / len(chunk_words) if chunk_words else 0
            
            print(f"[DEBUG] Fuzzy match check: {len(common_words)}/{len(chunk_words)} = {overlap_ratio:.2f}")
            
            # More restrictive: 90% overlap AND significant word count
            if (overlap_ratio >= 0.9 and len(common_words) >= 5):
                print(f"[DEBUG] FUZZY MATCH found at line {i} (overlap: {overlap_ratio:.2f})")
                return (i, [line])
    
    print(f"[DEBUG] No single line match found, trying multi-line...")
    
    # Multi-line matching with exclusion logic
    for i in range(start_idx, len(pdf_lines) - 1):
        line = pdf_lines[i]
        line_id = line.get("id", "")
        
        # Skip if starting line is already used
        if line_id in used_line_ids:
            continue
            
        combined_lines = [line]
        combined_text_parts = [line.get("text", "")]
        
        # Try combining with subsequent lines (up to 5 lines max)
        for j in range(i + 1, min(i + 6, len(pdf_lines))):
            next_line = pdf_lines[j]
            next_line_id = next_line.get("id", "")
            
            # ‚úÖ Skip if this line is already used
            if next_line_id in used_line_ids:
                print(f"[DEBUG] Skipping used line {next_line_id} in multi-line combination")
                break
                
            # Check if lines are on the same page and vertically close
            if (_lines_are_on_same_page(combined_lines[-1], next_line) and 
                _lines_are_vertically_close(combined_lines[-1], next_line)):
                
                combined_lines.append(next_line)
                combined_text_parts.append(next_line.get("text", ""))
                
                # Test if the combined text matches the chunk
                combined_text = " ".join(combined_text_parts)
                normalized_combined = _normalize(combined_text)
                
                print(f"[DEBUG] Testing {len(combined_lines)}-line combination")
                
                # Exact match with combined lines
                if normalized_chunk == normalized_combined:
                    print(f"[DEBUG] EXACT MULTI-LINE MATCH found starting at line {i}")
                    return (i, combined_lines)
                
                # Partial match (chunk contained in combined text)
                if normalized_chunk in normalized_combined:
                    print(f"[DEBUG] PARTIAL MULTI-LINE MATCH found starting at line {i}")
                    return (i, combined_lines)
                
                # Fuzzy match with combined text
                if len(normalized_chunk) > 15:
                    chunk_words = set(normalized_chunk.split())
                    combined_words = set(normalized_combined.split())
                    common_words = chunk_words & combined_words
                    overlap_ratio = len(common_words) / len(chunk_words) if chunk_words else 0
                    
                    if overlap_ratio >= 0.9 and len(common_words) >= 5:
                        print(f"[DEBUG] FUZZY MULTI-LINE MATCH found starting at line {i} (overlap: {overlap_ratio:.2f})")
                        return (i, combined_lines)
            else:
                # Lines are too far apart, stop combining
                print(f"[DEBUG] Lines too far apart, stopping combination at line {j}")
                break
    
    print(f"[DEBUG] No match found for chunk: '{chunk_text[:50]}...'")
    return None

def _calculate_chunk_box(matched_lines):
    """
    Calculate bounding box that encompasses all matched lines.
    Returns box dict with l, t, r, b coordinates.
    """
    if not matched_lines:
        return {"l": 0, "t": 0, "r": 0, "b": 0}
    
    # Flatten the matched_lines list in case it contains nested lists
    flattened_lines = []
    for item in matched_lines:
        if isinstance(item, list):
            # If item is a list of lines (from multi-line matching)
            flattened_lines.extend(item)
        else:
            # If item is a single line object
            flattened_lines.append(item)

    # Get all line boxes
    line_boxes = []
    for line in flattened_lines:
        if isinstance(line, dict) and "box" in line and line["box"]:
            line_boxes.append(line["box"])
    
    if not line_boxes:
        return {"l": 0, "t": 0, "r": 0, "b": 0}
    
    # Calculate encompassing box
    # t: top of first line (smallest t value)
    top = min(box.get("t", 0) for box in line_boxes)
    
    # b: bottom of last line (largest b value) 
    bottom = max(box.get("b", 0) for box in line_boxes)
    
    # l: leftmost position (smallest l value)
    left = min(box.get("l", 0) for box in line_boxes)
    
    # r: rightmost position (largest r value)
    right = max(box.get("r", 0) for box in line_boxes)
    
    return {
        "l": left,
        "t": top, 
        "r": right,
        "b": bottom
    }

def _match_chunk_to_lines(chunk_text, pdf_lines, start_idx=0):
    """
    Enhanced matching with multi-line support that returns both index and full line objects.
    Combines consecutive lines when needed to match chunks that span multiple lines.
    Always returns (index, [list_of_lines]) for consistency.
    """
    normalized_chunk = _normalize(chunk_text)
    
    # First try single line matches
    for i in range(start_idx, len(pdf_lines)):
        line = pdf_lines[i]
        line_text = line.get("text", "")
        normalized_line = _normalize(line_text)
        
        # Exact match
        if normalized_chunk == normalized_line:
            return (i, [line])
        
        # Partial match (chunk text contained in line)
        if normalized_chunk in normalized_line:
            return (i, [line])
        
        # Fuzzy match for minor differences
        if len(normalized_chunk) > 10:  # Only for substantial text
            common_words = set(normalized_chunk.split()) & set(normalized_line.split())
            if len(common_words) >= len(normalized_chunk.split()) * 0.8:  # 80% word overlap
                return (i, [line])
    
    # If no single line match, try multi-line matching
    for i in range(start_idx, len(pdf_lines) - 1):  # -1 because we need at least 2 lines
        combined_lines = [pdf_lines[i]]
        combined_text_parts = [pdf_lines[i].get("text", "")]
        
        # Try combining with subsequent lines (up to 5 lines max)
        for j in range(i + 1, min(i + 6, len(pdf_lines))):
            next_line = pdf_lines[j]
            
            # Check if lines are on the same page and vertically close
            if (_lines_are_on_same_page(combined_lines[-1], next_line) and 
                _lines_are_vertically_close(combined_lines[-1], next_line)):
                
                combined_lines.append(next_line)
                combined_text_parts.append(next_line.get("text", ""))
                
                # Test if the combined text matches the chunk
                combined_text = " ".join(combined_text_parts)
                normalized_combined = _normalize(combined_text)
                
                # Exact match with combined lines
                if normalized_chunk == normalized_combined:
                    return (i, combined_lines)
                
                # Partial match (chunk contained in combined text)
                if normalized_chunk in normalized_combined:
                    return (i, combined_lines)
                
                # Fuzzy match with combined text
                if len(normalized_chunk) > 10:
                    chunk_words = set(normalized_chunk.split())
                    combined_words = set(normalized_combined.split())
                    common_words = chunk_words & combined_words
                    if len(common_words) >= len(chunk_words) * 0.8:
                        return (i, combined_lines)
            else:
                # Lines are too far apart, stop combining
                break
    
    return None

def _lines_are_on_same_page(line1, line2):
    """Check if two lines are on the same page"""
    return line1.get("page") == line2.get("page")

def _lines_are_vertically_close(line1, line2, threshold_multiplier=2.0):
    """
    Check if two lines are vertically close enough to be considered continuous.
    Uses a more generous threshold for multi-line matching.
    """
    try:
        line1_box = line1.get("box", {})
        line2_box = line2.get("box", {})
        
        line1_bottom = line1_box.get("b", 0)
        line2_top = line2_box.get("t", 0)
        
        # Calculate line heights
        line1_height = line1_box.get("b", 0) - line1_box.get("t", 0)
        line2_height = line2_box.get("b", 0) - line2_box.get("t", 0)
        avg_height = (line1_height + line2_height) / 2
        
        # Gap between lines
        gap = line2_top - line1_bottom
        
        # Lines are close if gap is less than 2x average line height (more generous)
        return gap < (avg_height * threshold_multiplier) if avg_height > 0 else False
    except (KeyError, TypeError, ZeroDivisionError):
        return False
    
def _pdf_lines_for_match(structured):
    """
    Extract text lines from structured output, preserving line objects with metadata.
    """
    lines = []
    for element in structured:
        if element.get("type") == "text" and "text" in element:
            lines.append({
                "text": element["text"],
                "box": element.get("box", {}),
                "page": element.get("page", 1),
                "id": element.get("id", ""),
                "type": element.get("type", "text")
            })
        # Save the anchored result
        # with open("_pdf_lines_for_match_V1.json", "w") as f:
        #     json.dump(lines, f, indent=2)   
    return lines

@app.route('/test-anchoring', methods=['POST'])
def test_anchoring():
    """Test route to apply anchoring to existing output with real PDF data"""
    print("üß™ [DEBUG] /test-anchoring endpoint called!")
    
    if not request.is_json:
        return jsonify({"error": "Request must be JSON"}), 400
    
    data = request.get_json()
    simplified_view = data.get('simplified_view', '')
    structured = data.get('structured', [])
    source_filename = data.get('source_filename', 'unknown.pdf')  # Add this
    
    print(f"[DEBUG] Received structured data: {len(structured)} elements")
    print(f"[DEBUG] Source filename: {source_filename}")
    
    try:
        # Load your existing chunked output
        with open("sample_output.json", "r") as f:
            result = json.load(f)
        
        # print(f"[DEBUG] Loaded sample output with {len(result.get('chunks', []))} chunks")
        
        # Create empty image_bindings since you're not using OpenAI
        image_bindings = []
        
        # Apply anchoring with the real PDF structured data + filename
        anchored_chunks = _anchor_chunks_to_pdf(
            result.get("chunks", []), 
            structured, 
            image_bindings, 
            source_filename=source_filename
        )
        result["chunks"] = anchored_chunks
        
        # Add document-level metadata too
        result["document_metadata"] = {
            "source_file": source_filename,
            "processed_date": datetime.now().isoformat(),
            "total_chunks": len(anchored_chunks),
            "processing_version": "1.0",
            "anchored_chunks": sum(1 for chunk in anchored_chunks if chunk.get("metadata", {}).get("anchored", False)),
            "unanchored_chunks": sum(1 for chunk in anchored_chunks if not chunk.get("metadata", {}).get("anchored", False))
        }
        
        # Save the anchored result
        with open("anchored_output_V7.json", "w") as f:
            json.dump(result, f, indent=2)
        # print("[DEBUG] anchored_output.json created successfully")
        
        # print("\n[DEBUG] Anchored result (first chunk metadata):")
        # if anchored_chunks:
        #     print(json.dumps(anchored_chunks[0]["metadata"], indent=2))
        
        return jsonify(result), 200
        
    except FileNotFoundError:
        return jsonify({"error": "sample_output.json not found. Please ensure the file exists."}), 404
    except Exception as e:
        print(f"[ERROR] Error in test anchoring: {str(e)}")
        import traceback
        traceback.print_exc()
        return jsonify({"error": f"Internal server error: {str(e)}"}), 500

# Also add a simple route to just load and return your sample output:
@app.route('/load-sample', methods=['GET'])
def load_sample():
    """Load and return the sample output without anchoring"""
    try:
        with open("sample_output.json", "r") as f:
            result = json.load(f)
        return jsonify(result), 200
    except FileNotFoundError:
        return jsonify({"error": "sample_output.json not found"}), 404
    except Exception as e:
        return jsonify({"error": str(e)}), 500

# @app.route('/chunk-pdf', methods=['POST'])
# def chunk_pdf_content():
#     print("[DEBUG] Starting chunk_pdf_content function")

#     if not request.is_json:
#         print("[DEBUG] Request is not JSON")
#         return jsonify({"error": "Request must be JSON"}), 400
    
#     print("[DEBUG] Request is JSON, getting data...")
#     data = request.get_json()
#     simplified_view = data.get('simplified_view', '')
#     structured = data.get('structured', [])

#     print(f"[DEBUG] Data received - simplified_view length: {len(simplified_view)}, structured length: {len(structured)}")

#     # Collect images with payload
#     images = [el for el in structured if el.get("type") == "image" and el.get("image_b64")]
#     print(f"[DEBUG] Found {len(images)} images with base64 data")

#     # Optional debug
#     print(f"[DEBUG] /chunk-pdf: structured={len(structured)}, images(with b64)={len(images)}")

#     # --- Interleave text and images in the exact order of [IMAGE ...] markers ---
#     import re
#     image_pat = re.compile(r"\[IMAGE\s+page=(\d+)\s+l=([\d.]+)\s+t=([\d.]+)\s+r=([\d.]+)\s+b=([\d.]+)\]")

#     MAX_CHARS = 20000
#     MAX_IMAGES = 24
#     used_chars = 0
#     used_images = 0
#     contents = []
#     image_bindings = []

#     def push_text(txt: str):
#         nonlocal used_chars
#         if not txt:
#             return
#         remain = MAX_CHARS - used_chars
#         if remain <= 0:
#             return
#         chunk = txt[:remain]
#         contents.append({"type": "text", "text": chunk})
#         used_chars += len(chunk)

#     print("[DEBUG] About to process image markers...")

#     # Group available images by page
#     images_by_page = {}
#     for im in images:
#         p = im.get("page")
#         images_by_page.setdefault(p, []).append(im)

#     print(f"[DEBUG] Images grouped by page: {list(images_by_page.keys())}")

#     # Determine marker order per page (asc/desc by t) and sort images accordingly
#     # If markers decrease by t, use desc; else asc.
#     markers_by_page = {}
#     for m in image_pat.finditer(simplified_view):
#         p = int(m.group(1))
#         t = float(m.group(3))
#         markers_by_page.setdefault(p, []).append(t)

#     print(f"[DEBUG] Markers found on pages: {list(markers_by_page.keys())}")

#     def is_desc(ts):
#         # decide by majority of adjacent deltas
#         if len(ts) < 2:
#             return False
#         dec = sum(1 for i in range(1, len(ts)) if ts[i] < ts[i-1])
#         inc = sum(1 for i in range(1, len(ts)) if ts[i] > ts[i-1])
#         return dec > inc

#     for p, lst in images_by_page.items():
#         desc = is_desc(markers_by_page.get(p, []))
#         lst.sort(key=lambda e: e["box"]["t"], reverse=desc)

#     # Pointers per page to consume images in order
#     pointers = {p: 0 for p in images_by_page.keys()}

#     idx = 0
#     for m in image_pat.finditer(simplified_view):
#         start, end = m.span()
#         # text before the marker
#         push_text(simplified_view[idx:start])

#         page = int(m.group(1))

#         # Keep the marker text so structure remains visible to the model
#         push_text(simplified_view[start:end] + "\n")

#         # Attach next image for this page (by order)
#         if used_images < MAX_IMAGES and page in images_by_page:
#             pos = pointers.get(page, 0)
#             if pos < len(images_by_page[page]):
#                 im = images_by_page[page][pos]
#                 pointers[page] = pos + 1
#                 contents.append({
#                     "type": "image_url",
#                     "image_url": {"url": f"data:image/png;base64,{im['image_b64']}"}
#                 })
#                 image_bindings.append({"page": im.get("page"), "box": im.get("box")})
#                 used_images += 1

#         idx = end

#     # Trailing text after last marker (or whole text if no markers)
#     push_text(simplified_view[idx:])

#     # Debug
#     for p, lst in images_by_page.items():
#         print(f"[DEBUG] Page {p}: markers_used={pointers.get(p,0)} of {len(lst)} images")
#     print(f"[DEBUG] Interleaved -> text_chars={used_chars}, images_attached={used_images}")


#     # Messages array
#     messages = [
#         {
#             "role": "system",
#             "content": f"""You are a PDF content analyzer that outputs structured JSON.
#             Your task is to:
#             1. Analyze the input content (text and attached images).
#             2. Split it into logical chunks based on:
#                - Section boundaries
#                - Topic changes
#                - Visual formatting (headings, paragraphs, lists, tables, images)
#             3. Output a JSON object with the following schema:

#             {JSON_SCHEMA}

#             Formatting notes for the input you will receive:
#             - Inline markers in the text are **for your analysis only**. Do NOT include them in your final JSON output.
#             - Markers you may see:
#               *word* ‚Üí bold
#               _word_ ‚Üí italic
#               *_word_* ‚Üí bold+italic
#               <s=XX> ... </s> ‚Üí font size start/end
#             - These markers indicate formatting styles of the original document.
#             - Preserve the original text and line breaks exactly, but strip out these markers in your JSON output.
#             - For images, analyze the attached image content and provide `caption` and put it in text field + `context` in metadata.
#             - Always fill metadata fields: type, section, context (‚â§1 sentence), tags, continues, is_page_break, siblings, and page number.
#             """
#         },
#         {
#             "role": "user",
#             "content": contents if contents else [{"type": "text", "text": simplified_view[:MAX_CHARS]}]
#         }
#     ]

#     print(f"[DEBUG] Messages created. Content items: {len(contents)}")
#     print("[DEBUG] About to call GPT API...")



#     try:
#             # Call GPT-4o multimodal
#         response = client.chat.completions.create(
#             model="gpt-4o",
#             messages=messages,
#             response_format={ "type": "json_object" },
#             temperature=0.0
#         )

#         print("[DEBUG] GPT API call successful!")

#         print(f"\n[DEBUG] Raw GPT response content:")
#         print("=" * 50)
#         print(response.choices[0].message.content)
#         print("=" * 50)
        
#         result = json.loads(response.choices[0].message.content)

#         # Write sample output BEFORE any further processing
#         with open("sample_output.json", "w") as f:
#             json.dump(result, f, indent=2)
#         print("[DEBUG] sample_output.json created successfully")

#         # --- Map model chunks back to PDF positions (page + bbox) ---
#         anchored_chunks = _anchor_chunks_to_pdf(result.get("chunks", []), structured, image_bindings)
#         result["chunks"] = anchored_chunks
#         pprint(result)

#         # Debug log
#         print("\n[DEBUG] GPT Response:")
#         print("==================")
#         # print(json.dumps(result, indent=2))
#         print("==================\n")
#         return jsonify(result), 200
#     except json.JSONDecodeError as e:
#         print(f"\n[ERROR] Failed to parse JSON: {str(e)}")
#         print(f"Raw response: {response.choices[0].message.content}")
        
#         # Still try to save the raw response for debugging
#         try:
#             with open("raw_response.txt", "w") as f:
#                 f.write(response.choices[0].message.content)
#             print("[DEBUG] Saved raw response to raw_response.txt")
#         except Exception as save_err:
#             print(f"[ERROR] Could not save raw response: {save_err}")
            
#         return jsonify({"error": "Failed to parse model output as JSON"}), 500
#     except Exception as e:
#         print(f"\n[ERROR] Unexpected error: {str(e)}")
#         print(f"Error type: {type(e)}")
#         import traceback
#         traceback.print_exc()
#         return jsonify({"error": f"Internal server error: {str(e)}"}), 500


# You can also add a schema validator not a validator not sure yet
# Add date inside metadata later and the source file. 
JSON_SCHEMA = """{
  "chunks": [
    {
      "text": "string",
      "metadata": {
        "type": "heading|paragraph|list|table|image",
        "section": "string",
        "context": "string (maximum one sentence)",
        "tags": ["string"],
        "row_index": "integer (for tables only) or null",
        "continues": "boolean",
        "is_page_break": "boolean",
        "siblings": ["string"],  
        "page": "integer"
      }
    }
  ]
}"""



if __name__ == '__main__':
    app.run(debug=True)
